<!DOCTYPE HTML> <html itemscope="" xmlns="http://www.w3.org/1999/xhtml"> <head> <title>regressHhar</title> <meta content="refpage" name="chunktype"><meta content="function:regressHhar " itemprop="refentity" name="refentity"><meta content="fcn" itemprop="pagetype" name="toctype"><meta content="ref/function" itemprop="infotype" name="infotype" /><meta content="regressHhar Fits a multiple linear regression model with Harvey heteroskedasticity" itemprop="description" name="description" /><h1 itemprop="title">regressHhar</h1><script type="text/javascript"><!--   function Redirect() {var l = document.getElementById('link');l.click();   }   setTimeout('Redirect()', 400);//--></script></head> <a href="matlab:web([docrootFS '/FSDA/regressHhar.html'])"; target="_top" id="link">Link to formatted HTML documentation in Mathworks style of '/FSDA/regressHhar.html'</a> <P>If redirecting does not work you can see the proper HTML documentation of this page in Mathworks style at the web address of the Robust Statistics Academy of the University of Parma (RoSA)<P> <a href="http://rosa.unipr.it/FSDA/regressHhar.html">http://rosa.unipr.it/FSDA/regressHhar.html</a></P><hr /><p style="background-color:#A9CCE3 "><em>Syllabus page indexed by builddocsearchdb for function: regressHhar</em></p><P>regressHhar</P><P>Fits a multiple linear regression model with Harvey heteroskedasticity</P><h2>More About</h2><P>
   This routine implements Harvey’s (1976) model of
   multiplicative heteroscedasticity which is a very flexible, general
   model that includes most of the useful formulations as special cases.
   The general formulation is: 
   
       $\sigma^2_i =\sigma^2 \exp(z_i \alpha)$
   
   Let $z_i$ include a constant term so that \( z_i'=(1 \; q_i) \) where \( q_i \) is the
   original set of variables which are supposed to explain
   heteroscedasticity. This routine automatically adds a column of 1 to
   input matrix Z (therefore Z does not have to include a constant term).
   Now let 
   \[  
   \gamma'=[\log \sigma^2 \alpha'] = [ \gamma_0, \ldots, \gamma_r]. 
   \] 
   Then the model is simply
   \[
   \sigma^2_i = \exp(\gamma' z_i)
   \]
   Once the full parameter vector is estimated \( \exp( \gamma_0)\) provides the
   estimator for \( \sigma^2 \). 

  The model is:  
               \[
                 y=X \times\beta+ \epsilon,  \qquad 
                 \epsilon \sim N(0, \;  \Sigma)
               \]
               \[
                   \Sigma=diag(\sigma_1^2, ..., \sigma_n^2)    \qquad
                   \sigma_i^2=\exp(z_i^T \times \gamma)        \qquad
                   var(\epsilon_i)=\sigma_i^2                  \qquad
                   i=1, ..., n    
               \]                                                      
               $\beta$ = p-by-1 vector which contains regression
               parameters.                                                 
               $\gamma$ = (r+1)-times-1 vector $\gamma_0, \ldots,
               \gamma_r$ (or written in MATLAB language $(\gamma(1),
               \ldots, \gamma(r+1))$) which contains skedastic parameters.
               $X$ = n-by-p matrix containing explanatory variables in the
               mean equation (including the constant term if present).
               $Z$ = n-by-(r+1) matrix containing the explanatory
               variables in the skedastic equation. $Z= (z_1^T, \ldots,
               z_n^T)^T$ 
               $z_i^T=(1, z_{i,1}, \ldots, z_{i,r})$ (or written in MATLAB
               language  $z_i=(z(1), \ldots, z(r+1)$).
               REMARK1: given that the first element of $z_i$ is equal to 1
               $\sigma_i^2$ can be written as
               \[
               \sigma_i^2 = \sigma^2 \times \exp(z_i(2:r+1)*\gamma(2:r+1))
                          = \exp(\gamma(1))*\exp(z_i(2:r+1)*\gamma(2:r+1))
               \]
               that is, once the full parameter vector $\gamma$ containing
               the skedastic parameters is estimated $\exp( \gamma(1))$
               provides the estimator for $\sigma^2$. 
               REMARK2: if $Z=log(X)$ then
               \[
                            \sigma^2_i= \exp(z_i^T \times \gamma) =
                           \prod_{j=1}^p x_{ij}^{\gamma_j}     \qquad  
                            j=1, ..., p
               \]
               REMARK3: if there is just one explanatory variable (say $x
               =(x_1 \ldots, x_n)$) which is responsible for
               heteroskedasticity and the model is
               \[
               \sigma^2_i=( \sigma^2 \times x_i^\alpha)
               \]
               then it is necessary to supply $Z$ as $Z=log(x)$. In this
               case, given that the program automatically adds a column of
               ones to $Z$
               \[
                  \exp(Z(i,1) \times \gamma(1) +Z(i,2) \times \gamma(2))=
                  \exp(\gamma(1))*x_i^{\gamma(2)}
               \]
               therefore the $\exp$ of the first element of vector
               $\gamma$ (namely exp(gamma(1))) is the estimate of
               $\sigma^2$ while the second element of vector $\gamma$
               (namely gamma(2)) is the estimate of $\alpha$


</P><h2>References</h2><P>Greene W.H. (1987), Econometric Analysis, Prentice Hall. [5th edition,
   section 11.7.1 pp. 232-235, 7th edition, section  9.7.1 pp. 280-282].</P></html>